{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Neural Operators\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/padl-yonsei/blob/master/labs/04_neural_op_1d_burger.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we are going to look into the implementation of Fourier Neural Operators (FNO). As usual, let us first import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# print pytorch version and cuda version\n",
    "print(torch.__version__, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Transform\n",
    "\n",
    "The *Fourier Transform* is a powerful mathematical tool used to analyze signals and functions. It allows us to break down a complex signal (such as a sound wave or an image) into its basic building blocks: simple sinusoidal waves. Think of it as translating a signal from the *time domain* (how it changes over time) to the *frequency domain* (how much of each frequency is present in the signal). This is incredibly useful for tasks like signal processing, image analysis, and even solving differential equations.\n",
    "\n",
    "More formally, for a continuous signal $f(t)$, the Fourier Transform is defined as:\n",
    "\n",
    "$F(\\omega) = \\int_{-\\infty}^{\\infty} f(t) e^{-i \\omega t} \\, dt$\n",
    "\n",
    "- $f(t)$: The original signal in the time domain.\n",
    "- $F(\\omega)$: The transformed signal in the frequency domain.\n",
    "- $\\omega$: The angular frequency.\n",
    "- $e^{-i \\omega t} = \\cos(\\omega t) - i\\sin(\\omega t)$: A complex exponential (Euler's formula) that serves as the basis function.\n",
    "\n",
    "Consequently, the inverse *Fourier Transform*, which converts back from the frequency domain to the time domain, is given by:\n",
    "\n",
    "$f(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} F(\\omega) e^{i \\omega t} \\, d\\omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Fourier Transform (DFT) and Fast Fourier Transform (FFT)\n",
    "\n",
    "In practice, most signals are discrete rather than continuous, so we use the *Discrete Fourier Transform (DFT)*:\n",
    "\n",
    "$X_k = \\sum_{n=0}^{N-1} x_n e^{-i \\frac{2\\pi}{N} kn}$\n",
    "\n",
    "where:\n",
    "- $x_n$: The input signal of length $N$.\n",
    "- $X_k$: The frequency component at index $k$.\n",
    "- $k$: The frequency index.\n",
    "\n",
    "\n",
    "However, the DFT can be computationally expensive because, as in the formula, we will need to compute $N$ multiplications and additions *for every frequency component*. If there were $N$ frequency components, it would been that the computational complexity would be $O(N^2)$ which can be devastating for real-time applications or when $N$ is large.\n",
    "\n",
    "Thatâ€™s where the *Fast Fourier Transform (FFT)* comes in. The FFT is an optimized algorithm for computing the DFT much faster by exploiting symmetries in the DFT, reducing the computational complexity from $O(N^2)$ to $O(n \\log n)$. For example, for $N = 1024$, DFT requires $1,048,576$ operations, while FFT needs only $10,240$. This speedup makes it feasible to work with large signals in real-time applications like audio processing, communications, and data compression.\n",
    "\n",
    "For more about FFT, see [this book](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.03-Fast-Fourier-Transform.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT in PyTorch\n",
    "\n",
    "Now that we brushed up on the basics of Fourier Transform, DFT, and FFT, let us see how we could implement it in PyTorch. First, we generate a signal by combining two sine waves with wave lengths of 1/15 and 1/20 radians, respectively (or equivalently, frequencies of 15Hz and 20Hz):\n",
    "\n",
    "$x(t) = \\sin(\\frac{2\\pi x}{1/15}) + \\sin(\\frac{2\\pi y}{1/20}) = \\sin(30\\pi) + \\sin(40\\pi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = 1/50               # time step\n",
    "t = np.arange(0,10,Ts)  # 10 seconds\n",
    "x = np.sin(2*np.pi*15*t) + np.sin(2*np.pi*20*t)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(t, x)\n",
    "plt.xlim([0,10])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the good news is, PyTorch already comes with an implementation of FFT. So you don't need to implement it on your own (although it is not terribly difficult to do, if you want to get your hands dirty). Below is how you could perform FFT in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ft = torch.fft.fft(torch.tensor(x))\n",
    "fs = 1/Ts\n",
    "f = np.arange(len(x_ft))*fs/len(x_ft)  # frequency range\n",
    "plt.plot(f, np.abs(x_ft))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One weird thing you may have noticed is that the plot actually shows four frequency peaks, even though the signal we know has two frequencies at 15 Hz and 20 Hz. Here, the second half of the plot is actually the mirror reflection (comlex conjugates) of the first half. So the 30 Hz and 35 Hz components in the plot actually correspond to their mirror images -20 Hz and -15 Hz respectively.\n",
    "\n",
    "Hence, to better visualize considering this periodicity, you can use the `torch.fft.fftshift` function, which performs a circular shift on the transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x)\n",
    "f_shift = np.arange(-n/2,n/2)*(fs/n)    # shifted frequency range\n",
    "x_ft_shift = torch.fft.fftshift(x_ft)   # circular shift of the Fourier transform result\n",
    "plt.plot(f_shift, np.abs(x_ft_shift))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like what we just saw, Fourier Transform performed on real-valued signals will always return symmetric mirror images (complex conjugates) of the frequency components, which may be redundant. If you want to avoid this redundant representation, you could use the `torch.fft.rfft` function (notice the letter 'r' denoting 'real-valued') instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rft = torch.fft.rfft(torch.tensor(x))\n",
    "fs = 1/Ts\n",
    "f = np.arange(len(x_rft))*fs/len(x_rft)/2  # we only need the half of the frequency range now\n",
    "plt.plot(f, np.abs(x_rft))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse transform of `fft` and `rfft` are given as `ifft` and `irfft`, respectively (notice the letter 'i' that stands for 'inverse')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = torch.fft.ifft(x_ft)   # inverse of the regular transform \n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(t, x, c='black', label='Original')\n",
    "plt.plot(t, x_recon.numpy(), c='orange', label='Reconstructed')\n",
    "plt.xlim([0,10])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r_recon = torch.fft.irfft(x_rft)   # inverse of the real-valued transform \n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(t, x, c='black', label='Original')\n",
    "plt.plot(t, x_r_recon.numpy(), c='orange', label='Reconstructed')\n",
    "plt.xlim([0,10])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, one of the common uses of Fourier transform is for the compression of signal. Since we can now decompose a function into different frequency components, we can compress the data size of a signal by discarding insignificant, mostly noisy high-frequency components and keeping only low-frequency components. This is, in fact, a very popular way of compressing digital audio and image data, such as in JPEG and MP3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = 1./128                 # sampling rate 128 Hz\n",
    "t = np.arange(-5,5,Ts)\n",
    "x = np.exp(-t**2) + 0.03*np.random.randn(len(t))           # bell curve with noise\n",
    "\n",
    "plt.plot(t, x)\n",
    "plt.xlabel('Time (Seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rft = torch.fft.rfft(torch.tensor(x))\n",
    "fs = 1/Ts\n",
    "f = np.arange(len(x_rft))*fs/len(x_rft)/2  # we only need the half of the frequency range now\n",
    "plt.plot(f, np.abs(x_rft))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sampled = x_rft[:10]        # take the first 10 lowest frequency components and discard the rest\n",
    "\n",
    "temp = torch.zeros_like(x_rft)   # to reconstruct the signal we need the same number of elements as the original signal\n",
    "temp[:10] = down_sampled\n",
    "x_r_recon = torch.fft.irfft(temp)\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(t, x, c='black', label='Original')\n",
    "plt.plot(t, x_r_recon.numpy(), c='orange', label='Reconstructed', linewidth=3)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Convolution\n",
    "\n",
    "Fast Fourier transform we just saw above plays a critical role in neural operators as the means to perform neural network inference in the continuous function space (as opposed to discrete vector space). Below, we define the `SpectralConv1d` layer, which first maps a 1D signal to the frequency space via the Fourier transform, multiplies weights (as in typical neural nets), and pulls the neural net outputs back to the original space. This new layer will come handy in our implementation of the Fourier Neural Operator (FNO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_freqs):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_freqs = n_freqs  # Number of Fourier frequencies to be kept\n",
    "\n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        self.weights = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.n_freqs, dtype=torch.cfloat))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fourier Transform\n",
    "        x_ft = torch.fft.rfft(x) # [batch, channels, signal_length] -> [batch, channels, signal_length//2 + 1]\n",
    "        \n",
    "        # Weighted sum (neural network operation)\n",
    "        out_ft = torch.zeros(x.shape[0], self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.n_freqs] = torch.einsum(\"bix,iox->box\", x_ft[:, :, :self.n_freqs], self.weights)\n",
    "\n",
    "        # Inverse Fourier Transform\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Neural Operator (FNO)\n",
    "Now, here's the implementation of FNO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(FNO1d, self).__init__()\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(2, self.width) # 2 inputs: (x, a(x))\n",
    "\n",
    "        self.conv0 = SpectralConv1d(self.width, self.width, 16)\n",
    "        self.conv1 = SpectralConv1d(self.width, self.width, 16)\n",
    "        self.conv2 = SpectralConv1d(self.width, self.width, 16)\n",
    "        self.conv3 = SpectralConv1d(self.width, self.width, 16)\n",
    "\n",
    "        self.skip0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # output: u(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: map to a larger dimensional feature space\n",
    "        x = self.fc0(x)         # [Batch, Nx, C] -> [Batch, Nx, Width]\n",
    "        x = x.permute(0, 2, 1)  # [Batch, C, Nx]\n",
    "\n",
    "        # Step 2: Integral operators u' = (W + K)(u).\n",
    "        x = self.skip0(x) + self.conv0(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip1(x) + self.conv1(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip2(x) + self.conv2(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip3(x) + self.conv3(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        # Step 3: project from feature space to output space\n",
    "        x = x.permute(0, 2, 1)  # [Batch, Nx, C]\n",
    "        x = self.fc1(x)         # [Batch, Nx, C] -> [Batch, Nx, Width]\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)         # [Batch, Nx, C] -> [Batch, Nx, 1]\n",
    "        \n",
    "        # since there are only one output\n",
    "        x = x.squeeze(-1)       # [Batch, Nx, 1] -> [Batch, Nx]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application - 1D Burger's Equation\n",
    "\n",
    "Burger's equation is a fundamental partial differential equation in applied mathematics and physics, often used to model various phenomena such as fluid dynamics, gas dynamics, traffic flow, and acoustics. It combines elements of nonlinear advection and diffusion, making it a simplified model for understanding shock wave formation and viscous effects. The equation is particularly notable for its role as a prototype in studying nonlinear systems and turbulence, and it serves as a stepping stone for more complex equations like the Navier-Stokes equations. The equation is written as:\n",
    "\n",
    "$\\frac{\\partial u}{\\partial t} + u\\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2}$,\n",
    "\n",
    "where\n",
    "- $u(x,t)$ is the unknown function representing velocity or other conserved quantities\n",
    "- $\\nu$ is the viscosity (a positive constant)\n",
    "- $\\frac{\\partial u}{\\partial t}$ represents the time evolution\n",
    "- $u\\frac{\\partial u}{\\partial x}$ captures the nonlinear advection\n",
    "- $\\frac{\\partial^2 u}{\\partial x^2}$ accounts for the diffusive effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download\n",
    "url = \"https://www.dropbox.com/scl/fi/hy3volvnwa4p32t2w7pp8/1D_Burger.npz?rlkey=08x7dwfubz7n3si87f8w05q0f&st=0ljrr39o&dl=1\"\n",
    "filename = 'data/1D_Burger.npz'\n",
    "\n",
    "from pathlib import Path\n",
    "Path(\"data\").mkdir(exist_ok=True)  # create 'data' folder\n",
    "\n",
    "import os\n",
    "if not os.path.exists(filename):\n",
    "    # install and import wget library to download the data file\n",
    "    !pip install wget\n",
    "    import wget\n",
    "    wget.download(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(filename)\n",
    "A = raw_data['a']\n",
    "U = raw_data['u']\n",
    "\n",
    "N, L = A.shape\n",
    "\n",
    "# 1D grid\n",
    "X = np.tile(np.linspace(0, 1, L), (N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_rate = 32\n",
    "\n",
    "A_sampled = A[:, ::downsample_rate]\n",
    "U_sampled = U[:, ::downsample_rate]\n",
    "X_sampled = X[:, ::downsample_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.plot(X_sampled[i,:], A_sampled[i,:], color='black')\n",
    "plt.plot(X_sampled[i,:], U_sampled[i,:], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sampled = np.expand_dims(A_sampled, -1)\n",
    "X_sampled = np.expand_dims(X_sampled, -1)\n",
    "U_sampled = np.expand_dims(U_sampled, -1)\n",
    "\n",
    "data = torch.cat([torch.Tensor(X_sampled), torch.Tensor(A_sampled), torch.Tensor(U_sampled)], dim=2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = int(0.7*N)\n",
    "N_val = int(0.15*N)\n",
    "N_test = int(0.15*N)\n",
    "\n",
    "train_data, val_data, test_data = data[:N_train, :, :], data[N_train:N_train+N_val, :, :], data[-N_test:, :, :]\n",
    "\n",
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO1d(width=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "files = []\n",
    "import os\n",
    "save_dir = 'results/neural_operators/1d_burger'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "   \n",
    "MAX_ITER = 300\n",
    "for iter in range(MAX_ITER):\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(train_data[:,:,:2])\n",
    "    loss = torch.mean((train_data[:,:,2]-prediction)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    prediction = model(val_data[:,:,:2])\n",
    "    val_loss = torch.mean((val_data[:,:,2] - prediction)**2)\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().numpy():.5f}, val: {val_loss.detach().numpy():.5f}\", end='\\r')\n",
    "    \n",
    "    # plot a validation result as training progresses\n",
    "    if (iter+1) % 5 == 0: \n",
    "        idx = 0\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.plot(val_data[idx,:,0], val_data[idx,:,2], color='black', label = \"Ground Truth\")\n",
    "        plt.plot(val_data[idx,:,0], prediction[idx,:].detach(), color='deepskyblue', label = \"Neural Operator\")\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"u\")\n",
    "        plt.title(f'Iteration={iter+1}')\n",
    "        plt.legend()\n",
    "        \n",
    "        file = os.path.join(save_dir, \"fno_%.6i.png\"%(iter+1))\n",
    "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "        files.append(file)\n",
    "    \n",
    "        if (iter+1) % 20 == 0: plt.show()\n",
    "        else: plt.close(\"all\")\n",
    "\n",
    "from PIL import Image\n",
    "fps = 20\n",
    "imgs = [Image.open(file) for file in files]\n",
    "imgs[0].save(fp=\"results/neural_operators/FNO_1d_burger.gif\", format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://github.com/xiaoyuxie-vico/Sci-ML-Book/blob/main/FNO/FNO-1D/FNO-1D.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
