{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Aware Recurrent Convolutions\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/padl-yonsei/blob/master/labs/05_parc_harmonic_oscillator.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a> <br/>\n",
    "\n",
    "While the physics-aware deep learning methods we've seen so far, including PINN and Neural Operators, provided mathematically more rigorous way of fitting neural networks to dynamics data, they are also known to be biased towards low-frequency, \"relatively linear\" dynamics phenomena. For problems that involve strong nonlinear behaviors or stiffness, such as high frequency features, sharp gradients, fast-transient features, discontinuities, etc., physics-aware recurrent convolutions (PARC) might be a more reliable choice. In this session, we will revisit the problem of modeling harmonic oscillators using neural networks, but this time with a greater frequency, and compare PINN, neural operators, and PARC on the problem with the increased stiffness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on (Damped) Harmonic Oscillators\n",
    "\n",
    "Here, we brush up again on the basic theories of harmonic oscillators.\n",
    "\n",
    "In classical mechanics, a harmonic oscillator is a system in which a mass experiences a restoring force proportional to its displacement from equilibrium. If we let $x$ be the displacement of the mass $m$ from the equilibrium $x=0$, by the Hooke's law, the restoring force $F_r$ has the following form:\n",
    "\n",
    "$$F_r=-kx.$$\n",
    "\n",
    "Also, from the Newton's second law of motion $F=m\\frac{\\partial^2 x}{\\partial t^2}$, where the second order derivative with respect to time $t$, we have the following relationship:\n",
    "\n",
    "$$m\\frac{\\partial^2 x}{\\partial t^2} + kx = 0.$$\n",
    "\n",
    "In an ideal harmonic oscillator as in the above, the mass oscillates indefinitely with constant amplitude and frequency. However, real-world oscillators are often damped and experience a resistive or damping force that opposes its motion. This means that they gradually lose energy due to frictional or resistive forces, causing the oscillations to decrease in amplitude over time. Such a damping force, say $F_d$ can be modeled as being proportional to the velocity $\\frac{\\partial x}{\\partial t}$ of the mass, or $F_d=-c\\frac{\\partial x}{\\partial t}$, where $c$ is called the damping coefficient.\n",
    "\n",
    "The Newton's second law for damped harmonic oscillators then becomes:\n",
    "\n",
    "$$F_\\text{total} = F_r + F_d = -kx-c\\frac{\\partial x}{\\partial t} = m\\frac{\\partial^2 x}{\\partial t^2},$$\n",
    "\n",
    "which can be rewritten into a more intuitive form:\n",
    "\n",
    "$$\\frac{\\partial^2 x}{\\partial t^2} + 2\\zeta\\omega_0\\frac{\\partial x}{\\partial t} + \\omega_0^2 x = 0,$$\n",
    "\n",
    "where $\\omega_0:=\\sqrt{\\frac{k}{m}}$ is the angular frequency of the oscillator and $\\zeta:=\\frac{c}{2\\sqrt{mk}}$ is called the damping ratio.\n",
    "\n",
    "The value of the damping ratio can vary and critically determine the behavior of the system, affecting whether the system returns to equilibrium without oscillating (overdamping; $\\zeta>1$), oscillates with a gradually reducing amplitude (underdamping; $\\zeta<1$), or quickly comes to rest without oscillating (critical damping; $\\zeta=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, it is more convenient to use the state space representation of a damped harmonic oscillator, expressesing the system's dynamics using a set of first-order differential equations that describe its state at any given time. The state vector, typically represented by $\\mathbf{x}(t)$, includes position $x$ and velocity $\\dot{x}:=\\frac{\\partial x}{\\partial t}$, which fully describe the system's current condition:\n",
    "\n",
    "$$\\mathbf{x}(t) = \\begin{bmatrix} x(t) \\\\ \\dot{x}(t) \\end{bmatrix}.$$\n",
    "\n",
    "Then the original second-order differential equation of the harmonic oscillator above then becomes a system of first-order differential equations:\n",
    "\n",
    "$$\\frac{d}{dt}\\mathbf{x}(t)=\\begin{bmatrix} 0 & 1 \\\\ -2\\zeta\\omega_0 & -\\omega_0^2\\end{bmatrix}\\mathbf{x}(t)$$\n",
    "\n",
    "where the matrix \n",
    "$$A:=\\begin{bmatrix} 0 & 1 \\\\ -2\\zeta\\omega_0 & -\\omega_0^2\\end{bmatrix}$$\n",
    "is called the system matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the underdamped or critically damped cases where $\\zeta \\leq 1$, the analytical solution for the state space representation of a damped harmonic oscillator can be expressed as damped sinusoidal oscillations:\n",
    "\n",
    "$$\\mathbf{x}(t) = ae^{-\\zeta\\omega_0 t}\\sin(\\sqrt{1-\\zeta^2}\\omega_0t + \\varphi),$$\n",
    "\n",
    "where the amplitude $a$ and phase $\\varphi$ are coefficients determined from the initial conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n",
    "Building upon the theoretical background above, let's generate data for training and validating neural networks. Notice that most of the code below are reused from the previous sessions, except that we have a higher angular frequency ($\\omega_0$) and lower damping ratio ($\\zeta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import IPython.display\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "def save_progress(save_dir, prefix, i):\n",
    "    file = os.path.join(save_dir, prefix + \"_%.6i.png\"%(i+1))\n",
    "    plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "    return file\n",
    "\n",
    "def make_gif(imagefiles, output_path, fps=20):\n",
    "    imgs = [Image.open(file) for file in imagefiles]\n",
    "    imgs[0].save(fp=output_path, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=True)\n",
    "\n",
    "def reset_parameters(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineCoefficients(X0, zeta, omega0):\n",
    "    ''' Determine amplitude a and phase phi.\n",
    "\n",
    "    Inputs:\n",
    "        X0: torch.tensor of size (2,) containing initial position and velocity.\n",
    "        zeta: damping ratio.\n",
    "        omega0: angular frequency.\n",
    "\n",
    "    Returns:\n",
    "        Amplitude a and phase phi that match the initial condition X0.\n",
    "    '''\n",
    "    assert zeta <= 1, \"zeta must be under-/critically-damped (zeta <= 1)\"\n",
    "\n",
    "    if torch.abs((X0[1] + zeta*omega0*X0[0])) < 1e-7:\n",
    "        phi = 0.5*torch.pi\n",
    "    else:\n",
    "        num = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0*X0[0]\n",
    "        den = X0[1] + zeta*omega0*X0[0]\n",
    "        phi = torch.arctan(num/den)\n",
    "    a = X0[0]/torch.sin(phi)\n",
    "\n",
    "    return a, phi\n",
    "\n",
    "# Conventional numerical solver for comparison\n",
    "def ode(X, t, omega0, zeta):\n",
    "    \"\"\"\n",
    "    X = [x, dx]: State vector\n",
    "    omega0 = sqrt(k/m): Undamped angular frequency of the oscillator.\n",
    "    beta = 0.5*c/sqrt(m*k): Damping ratio.\n",
    "    \"\"\"\n",
    "    x, dx = X\n",
    "    ddx = -2*zeta*omega0*dx - (omega0**2)*x\n",
    "    return [dx, ddx]\n",
    "\n",
    "\n",
    "# Initial condition\n",
    "X0 = torch.tensor([1, 0], dtype=dtype)   # initial condition\n",
    "omega0 = 40#2*torch.pi                      # angular frequency\n",
    "zeta = 0.03#0.03                               # damping ratio (<= 1)\n",
    "\n",
    "# Determine coefficients\n",
    "a, phi = determineCoefficients(X0, zeta, omega0)\n",
    "\n",
    "# Create ground truth data\n",
    "Nt = 1024    # number of time steps\n",
    "Tmax = 1\n",
    "t = torch.linspace(0, Tmax, Nt, dtype=dtype)\n",
    "\n",
    "# Compute the analytic solution (ground truth) for the state x(t) and the velocity dx/dt\n",
    "ezot = torch.exp(-zeta*omega0*t)\n",
    "sqrt_omega = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0\n",
    "position = a*ezot*torch.sin(sqrt_omega*t + phi)\n",
    "velocity = -a*zeta*omega0*ezot*np.sin(sqrt_omega*t + phi) + a*ezot*sqrt_omega*np.cos(sqrt_omega*t + phi)\n",
    "GT = torch.stack([position, velocity]).T\n",
    "\n",
    "# Numerical Solution - ODE Solver\n",
    "X = integrate.odeint(ode, X0, t, args = (omega0, zeta))\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.plot(t, X[:,0], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t, GT[:,1], color='black', label = \"Ground Truth\")\n",
    "plt.plot(t, X[:,1], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"dx/dt\")\n",
    "plt.title('Velocity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_sample = 0.5       # maximum time for training sample\n",
    "sample_stride = 8       # stride between samples\n",
    "\n",
    "Nt_sample = int(Nt*Tmax_sample/Tmax)\n",
    "\n",
    "t_sample = torch.unsqueeze(t[0:Nt_sample:sample_stride], -1)\n",
    "GT_sample = GT[0:Nt_sample:sample_stride,:]\n",
    "\n",
    "training_data = torch.hstack((t_sample, GT_sample))  # t, x\n",
    "training_data[:,1] += torch.randn(len(training_data))*0.01 # Emulate noisy observations\n",
    "training_data[:,2] += torch.randn(len(training_data))*0.01  #\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.plot(t, X[:,0], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t, GT[:,1], color='black', label = \"Ground Truth\")\n",
    "plt.plot(t, X[:,1], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "plt.scatter(training_data[:,0], training_data[:,2], color='orange', label='Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"dx/dt\")\n",
    "plt.title('Velocity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PINN\n",
    "\n",
    "Let's first start with PINN. A few sessions ago, we saw that PINN worked quite well in modeling harmonic oscillators with a lower frequency and stronger damping. Well, this time, like we just saw above, we have a system that is more stiff with reduced damping and increased frequency of oscillation. Let's see how PINN behaves on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, dtype=dtype):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(1, 32, dtype=dtype)  # input dim = 1 (t)\n",
    "        self.fc2 = nn.Linear(32, 32, dtype=dtype)  # hidden dims = 64, 64\n",
    "        self.fc3 = nn.Linear(32, 32, dtype=dtype)  #\n",
    "        self.out = nn.Linear(32, 1, dtype=dtype)  # output dim = 1 (x)\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = nn.SiLU()(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = nn.SiLU()(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = nn.SiLU()(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model = Backbone().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.5)\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic_stiff/pinn'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 200000\n",
    "N_COLLOCATION_POINTS = 60\n",
    "Trange=len(training_data)\n",
    "# Trange=1\n",
    "input = training_data[:Trange,:1].clone().to(device)    # t\n",
    "output = training_data[:Trange,1:2].clone().to(device)  # x\n",
    "collocation_t = torch.linspace(0,Tmax,N_COLLOCATION_POINTS)\n",
    "collocation_pts = torch.unsqueeze(collocation_t, -1).clone().requires_grad_(True).to(device)\n",
    "viz_t = torch.unsqueeze(t,axis=-1).clone().requires_grad_(True).to(device)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    data_loss = torch.mean((output-prediction)**2)\n",
    "    \n",
    "    prediction_colloc = model(collocation_pts)\n",
    "    dx  = torch.autograd.grad(prediction_colloc, collocation_pts, torch.ones_like(prediction_colloc), create_graph=True)[0]\n",
    "    ddx  = torch.autograd.grad(dx, collocation_pts, torch.ones_like(dx), create_graph=True)[0]\n",
    "    residual = ddx + 2*zeta*omega0*dx + (omega0**2)*prediction_colloc\n",
    "    physics_loss = torch.mean(residual**2)\n",
    "    loss = 10000*data_loss + (1e-4)*physics_loss\n",
    "    # loss = data_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}, physics_1: {physics_loss.detach().cpu().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 1000 == 0: \n",
    "        prediction = model(viz_t)\n",
    "        dx  = torch.autograd.grad(prediction, viz_t, torch.ones_like(prediction))[0]\n",
    "\n",
    "        plt.figure(figsize=(16,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,0], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(t, prediction[:,0].detach().cpu(), color='deepskyblue', label = \"PINN\")\n",
    "        plt.scatter(collocation_t, np.zeros_like(collocation_t), color='olive', label = \"Collocation Points\", s=10)\n",
    "        plt.scatter(training_data[:Trange,0], training_data[:Trange,1], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"x\")\n",
    "        plt.title(f'Position (Iteration={iter+1})')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(t, GT[:,1], color='black', label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,1], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(t, dx.detach().cpu(), color='deepskyblue', label = \"PINN\")\n",
    "        plt.scatter(collocation_t, np.zeros_like(collocation_t), color='olive', label = \"Collocation Points\", s=10)\n",
    "        plt.scatter(training_data[:Trange,0], training_data[:Trange,2], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"dx/dt\")\n",
    "        plt.title('Velocity')\n",
    "        plt.legend()\n",
    "\n",
    "        files.append(save_progress(save_dir, 'pinn', iter))\n",
    "    \n",
    "        if (iter+1) % 10000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic_stiff/pinn_stiff.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic_stiff/pinn_stiff.gif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_freqs):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_freqs = n_freqs  # Number of Fourier frequencies to be kept\n",
    "\n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        self.weights = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.n_freqs, dtype=torch.cfloat))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Fourier Transform\n",
    "        x_ft = torch.fft.rfft(x) # [batch, channels, signal_length] -> [batch, channels, signal_length//2 + 1]\n",
    "        \n",
    "        # Weighted sum (neural network operation)\n",
    "        out_ft = torch.zeros(x.shape[0], self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.n_freqs] = torch.einsum(\"bix,iox->box\", x_ft[:, :, :self.n_freqs], self.weights)\n",
    "\n",
    "        # Inverse Fourier Transform\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "    \n",
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(FNO1d, self).__init__()\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(2, self.width) # Inputs: time series (x, dx/dt) for the first few time steps\n",
    "\n",
    "        n_freq = 8\n",
    "        self.conv0 = SpectralConv1d(self.width, self.width, n_freq)\n",
    "        self.conv1 = SpectralConv1d(self.width, self.width, n_freq)\n",
    "        self.conv2 = SpectralConv1d(self.width, self.width, n_freq)\n",
    "        self.conv3 = SpectralConv1d(self.width, self.width, n_freq)\n",
    "\n",
    "        self.skip0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.skip3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Outputs: time series (x, dx/dt) for the following time steps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: map to a larger dimensional feature space\n",
    "        x = self.fc0(x)         # [Batch, Nx, C] -> [Batch, Nx, Width]\n",
    "        x = x.permute(0, 2, 1)  # [Batch, C, Nx]\n",
    "\n",
    "        # Step 2: Integral operators u' = (W + K)(u).\n",
    "        x = self.skip0(x) + self.conv0(x)\n",
    "        # x = nn.Tanh()(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip1(x) + self.conv1(x)\n",
    "        # x = nn.Tanh()(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip2(x) + self.conv2(x)\n",
    "        # x = nn.Tanh()(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        x = self.skip3(x) + self.conv3(x)\n",
    "        # x = nn.Tanh()(x)\n",
    "        x = nn.SiLU()(x)\n",
    "\n",
    "        # Step 3: project from feature space to output space\n",
    "        x = x.permute(0, 2, 1)  # [Batch, Nx, C]\n",
    "        x = self.fc1(x)         # [Batch, Nx, C] -> [Batch, Nx, Width]\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)         # [Batch, Nx, C] -> [Batch, Nx, 1]\n",
    "        \n",
    "        # since there are only one output\n",
    "        x = x.squeeze(-1)       # [Batch, Nx, 1] -> [Batch, Nx]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = FNO1d(width=64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-5)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.8)\n",
    "\n",
    "files = []\n",
    "import os\n",
    "save_dir = 'results/harmonic_stiff/fno'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "   \n",
    "MAX_ITER = 20000\n",
    "fno_window = len(training_data)//2\n",
    "input = torch.unsqueeze(training_data[0:fno_window,1:].clone(), 0).to(device)    # x, dx/dt @ first 32 frames\n",
    "output = training_data[fno_window:2*fno_window,1:].clone().to(device)             # x, dx/dt for the next 32 frames\n",
    "for iter in range(MAX_ITER):\n",
    "    model.train(True)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)[0]\n",
    "    loss = torch.mean((output[:,0]-prediction[:,0])**2) + 0.0001*torch.mean((output[:,1]-prediction[:,1])**2)\n",
    "    # loss = torch.mean((output-prediction)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # roll out the prediction\n",
    "    if (iter+1) % 100 == 0: \n",
    "        # viz_t = torch.unsqueeze(t,axis=-1).clone().requires_grad_(True)\n",
    "        viz_t = training_data[0:fno_window,0:1].clone()\n",
    "        sequence = input.clone()\n",
    "        for i in range(3):\n",
    "            model.train(False)\n",
    "            prediction = model(sequence[:,-fno_window:,:])\n",
    "            sequence = torch.cat([sequence, prediction], dim=1)\n",
    "            viz_t = torch.cat([viz_t, training_data[0:fno_window,0:1] + viz_t[-1,0] + viz_t[1,0]], dim=0)\n",
    "\n",
    "        plt.figure(figsize=(16,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,0], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(viz_t, sequence[0,:,0].detach().cpu(), color='deepskyblue', label = \"FNO\")\n",
    "        plt.scatter(training_data[:fno_window*2,0], training_data[:fno_window*2,1], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"x\")\n",
    "        plt.title(f'Position (Iteration={iter+1})')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(t, GT[:,1], color='black', label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,1], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(viz_t, sequence[0,:,1].detach().cpu(), color='deepskyblue', label = \"FNO\")\n",
    "        plt.scatter(training_data[:fno_window*2,0], training_data[:fno_window*2,2], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"dx/dt\")\n",
    "        plt.title('Velocity')\n",
    "        plt.legend()\n",
    "\n",
    "        files.append(save_progress(save_dir, 'fno', iter))\n",
    "    \n",
    "        if (iter+1) % 1000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic_stiff/fno_stiff.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic_stiff/fno_stiff.gif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Differentiator(nn.Module):\n",
    "    def __init__(self, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(2, 32, dtype=dtype)  # input dim = 2 (x, dx)\n",
    "        self.fc2 = nn.Linear(32, 16, dtype=dtype)  # hidden dims = 16, 16\n",
    "        self.out = nn.Linear(16, 2, dtype=dtype)  # output dim = 2 (dx, ddx)\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = nn.SiLU()(x) \n",
    "        x = nn.LeakyReLU()(x) \n",
    "        x = self.fc2(x)\n",
    "        # x = nn.SiLU()(x) \n",
    "        x = nn.LeakyReLU()(x) \n",
    "        return self.out(x)\n",
    "    \n",
    "diff = Differentiator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(diff)\n",
    "\n",
    "optimizer = torch.optim.Adam(diff.parameters(), lr=1e-4)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.8)\n",
    "\n",
    "files = []\n",
    "import os\n",
    "save_dir = 'results/harmonic_stiff/parc'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "\n",
    "MAX_ITER = 10000\n",
    "dt = training_data[1,0].clone().to(device)\n",
    "X0_device = X0.clone().to(device)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    x = X0_device\n",
    "    for i in range(len(training_data)-1):\n",
    "        # dx0 = diff(x)\n",
    "        # dx1 = diff(x + dt*dx0)\n",
    "        # x = x + 0.5*dt*(dx0 + dx1)\n",
    "        pred_dx = diff(x)\n",
    "        x = x + pred_dx*dt   # simple forward Euler should work fine for this toy example\n",
    "        if i == 0:\n",
    "            loss = (x[0] - training_data[i+1,1])**2 + 0.001*(x[1] - training_data[i+1,2])**2\n",
    "            # loss = torch.abs(x[0] - training_data[i+1,1]) + torch.abs(x[1] - training_data[i+1,2])\n",
    "        else:\n",
    "            loss += (x[0] - training_data[i+1,1])**2 + 0.001*(x[1] - training_data[i+1,2])**2\n",
    "            # loss += torch.abs(x[0] - training_data[i+1,1]) + torch.abs(x[1] - training_data[i+1,2])\n",
    "    loss /= len(training_data)-1\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        x = X0_device\n",
    "        prediction = [[0, x[0].detach().cpu().numpy(), x[1].detach().cpu().numpy()]]\n",
    "        for i in range(len(training_data)*2):\n",
    "            pred_dx = diff(x)\n",
    "            x = x + pred_dx*dt\n",
    "            # dx0 = diff(x)\n",
    "            # dx1 = diff(x + dt*dx0)\n",
    "            # x = x + 0.5*dt*(dx0 + dx1)\n",
    "            prediction.append([i*dt.detach().cpu().numpy(), x[0].detach().cpu().numpy(), x[1].detach().cpu().numpy()])\n",
    "        prediction = np.array(prediction)\n",
    "\n",
    "        plt.figure(figsize=(16,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,0], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(prediction[:,0], prediction[:,1], color='deepskyblue', label = \"PARC\")\n",
    "        plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"x\")\n",
    "        plt.title(f'Position (Iteration={iter+1})')\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(t, GT[:,1], color='black',     label = \"Ground Truth\")\n",
    "        # plt.plot(t, X[:,1], color='crimson', linestyle='dashed', label = \"ODE Solver\")\n",
    "        plt.plot(prediction[:,0], prediction[:,2], color='deepskyblue', label = \"PARC\")\n",
    "        plt.scatter(training_data[:,0], training_data[:,2], color='orange', label='Training Data')\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"t\")\n",
    "        plt.ylabel(\"dx/dt\")\n",
    "        plt.title('Velocity')\n",
    "        plt.legend()\n",
    "        \n",
    "        file = os.path.join(save_dir, \"parc_%.6i.png\"%(iter+1))\n",
    "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "        files.append(file)\n",
    "    \n",
    "        if (iter+1) % 500 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic_stiff/parc_stiff.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic_stiff/parc_stiff.gif\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
