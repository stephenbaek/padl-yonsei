{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks - Harmonic Oscillator\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/stephenbaek/padl-yonsei/blob/master/labs/03_pinn_harmonic_oscillator.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import IPython.display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "# Helper functions\n",
    "def save_progress(save_dir, prefix, i):\n",
    "    file = os.path.join(save_dir, prefix + \"_%.6i.png\"%(i+1))\n",
    "    plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
    "    return file\n",
    "\n",
    "def make_gif(imagefiles, output_path, fps=20):\n",
    "    imgs = [Image.open(file) for file in imagefiles]\n",
    "    imgs[0].save(fp=output_path, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=True)\n",
    "\n",
    "def reset_parameters(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on (Damped) Harmonic Oscillators\n",
    "\n",
    "In classical mechanics, a harmonic oscillator is a system in which a mass experiences a restoring force proportional to its displacement from equilibrium. If we let $x$ be the displacement of the mass $m$ from the equilibrium $x=0$, by the Hooke's law, the restoring force $F_r$ has the following form:\n",
    "\n",
    "$$F_r=-kx.$$\n",
    "\n",
    "Also, from the Newton's second law of motion $F=m\\frac{\\partial^2 x}{\\partial t^2}$, where the second order derivative with respect to time $t$, we have the following relationship:\n",
    "\n",
    "$$m\\frac{\\partial^2 x}{\\partial t^2} + kx = 0.$$\n",
    "\n",
    "In an ideal harmonic oscillator as in the above, the mass oscillates indefinitely with constant amplitude and frequency. However, real-world oscillators are often damped and experience a resistive or damping force that opposes its motion. This means that they gradually lose energy due to frictional or resistive forces, causing the oscillations to decrease in amplitude over time. Such a damping force, say $F_d$ can be modeled as being proportional to the velocity $\\frac{\\partial x}{\\partial t}$ of the mass, or $F_d=-c\\frac{\\partial x}{\\partial t}$, where $c$ is called the damping coefficient.\n",
    "\n",
    "The Newton's second law for damped harmonic oscillators then becomes:\n",
    "\n",
    "$$F_\\text{total} = F_r + F_d = -kx-c\\frac{\\partial x}{\\partial t} = m\\frac{\\partial^2 x}{\\partial t^2},$$\n",
    "\n",
    "which can be rewritten into a more intuitive form:\n",
    "\n",
    "$$\\frac{\\partial^2 x}{\\partial t^2} + 2\\zeta\\omega_0\\frac{\\partial x}{\\partial t} + \\omega_0^2 x = 0,$$\n",
    "\n",
    "where $\\omega_0:=\\sqrt{\\frac{k}{m}}$ is the angular frequency of the oscillator and $\\zeta:=\\frac{c}{2\\sqrt{mk}}$ is called the damping ratio.\n",
    "\n",
    "The value of the damping ratio can vary and critically determine the behavior of the system, affecting whether the system returns to equilibrium without oscillating (overdamping; $\\zeta>1$), oscillates with a gradually reducing amplitude (underdamping; $\\zeta<1$), or quickly comes to rest without oscillating (critical damping; $\\zeta=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Ground Truth (Analytic Solution)\n",
    "\n",
    "In the underdamped or critically damped cases where $\\zeta \\leq 1$, the analytical solution for the state space representation of a damped harmonic oscillator can be expressed as damped sinusoidal oscillations:\n",
    "\n",
    "$$\\mathbf{x}(t) = ae^{-\\zeta\\omega_0 t}\\sin(\\sqrt{1-\\zeta^2}\\omega_0t + \\varphi),$$\n",
    "\n",
    "where the amplitude $a$ and phase $\\varphi$ are coefficients determined from the initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineCoefficients(X0, zeta, omega0):\n",
    "    ''' Determine amplitude a and phase phi.\n",
    "\n",
    "    Inputs:\n",
    "        X0: torch.tensor of size (2,) containing initial position and velocity.\n",
    "        zeta: damping ratio.\n",
    "        omega0: angular frequency.\n",
    "\n",
    "    Returns:\n",
    "        Amplitude a and phase phi that match the initial condition X0.\n",
    "    '''\n",
    "    assert zeta <= 1, \"zeta must be under-/critically-damped (zeta <= 1)\"\n",
    "\n",
    "    if torch.abs((X0[1] + zeta*omega0*X0[0])) < 1e-7:\n",
    "        phi = 0.5*torch.pi\n",
    "    else:\n",
    "        num = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0*X0[0]\n",
    "        den = X0[1] + zeta*omega0*X0[0]\n",
    "        phi = torch.arctan(num/den)\n",
    "    a = X0[0]/torch.sin(phi)\n",
    "\n",
    "    return a, phi\n",
    "\n",
    "\n",
    "# Initial condition\n",
    "X0 = torch.tensor([1, 0], dtype=dtype)   # initial condition\n",
    "omega0 = 2*torch.pi                      # angular frequency\n",
    "zeta = 0.15                               # damping ratio (<= 1)\n",
    "\n",
    "# Determine coefficients\n",
    "a, phi = determineCoefficients(X0, zeta, omega0)\n",
    "\n",
    "# Create ground truth data\n",
    "Nt = 1000    # number of time steps\n",
    "Tmax = 3\n",
    "t = torch.linspace(0, Tmax, Nt, dtype=dtype)\n",
    "\n",
    "# Compute the analytic solution (ground truth) for the state x(t)\n",
    "ezot = torch.exp(-zeta*omega0*t)\n",
    "sqrt_omega = torch.sqrt(torch.tensor(1-zeta**2, dtype=dtype))*omega0\n",
    "position = a*ezot*torch.sin(sqrt_omega*t + phi)\n",
    "GT = torch.unsqueeze(position,-1)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training data\n",
    "\n",
    "Now to train a model, let's sample training data. Here, we are going to assume a scenario where we only have a partial and discrete observation of the dynamics in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_sample = 1.2       # maximum time for training sample\n",
    "sample_stride = 20       # stride between samples\n",
    "\n",
    "Nt_sample = int(Nt*Tmax_sample/Tmax)\n",
    "\n",
    "t_sample = torch.unsqueeze(t[0:Nt_sample:sample_stride], -1)\n",
    "GT_sample = GT[0:Nt_sample:sample_stride,:]\n",
    "\n",
    "training_data = torch.hstack((t_sample, GT_sample))  # t, x\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design\n",
    "\n",
    "Now, let's design a model. Here, I'm providing a simple MLP implementation as a starter. But you are encouraged to experiment with different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(1, 32, dtype=dtype)  # input dim = 1 (t)\n",
    "        self.fc2 = nn.Linear(32, 32, dtype=dtype)  # hidden dims = 32, 32\n",
    "        self.fc3 = nn.Linear(32, 32, dtype=dtype)  #\n",
    "        self.out = nn.Linear(32, 1, dtype=dtype)  # output dim = 1 (x)\n",
    "\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.SiLU()(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "model = Backbone().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training WITHOUT Physics-Informed Loss Term\n",
    "\n",
    "Before we get started with PINN, we'll set up a simple training session without any physics informed loss terms to set a baseline. Of course, a physics-naive model would'nt generalize well beyond the observed range of dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(t, GT, prediction, training_data, collocation_t=None):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(t, GT, color='black', label = \"Ground Truth\")\n",
    "    plt.plot(t, prediction, color='deepskyblue', label = \"PINN\")\n",
    "    plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "    if not collocation_t is None:\n",
    "        plt.scatter(collocation_t, torch.zeros_like(collocation_t), color='olive', label = \"Collocation Points\", s=20)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"x\")\n",
    "    plt.title(f'Position (Iteration={iter+1})')\n",
    "    plt.legend()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic/nophysics'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 30000\n",
    "input = training_data[:,:1].clone().detach().to(device)    # t\n",
    "output = training_data[:,1:].clone().detach().to(device)  # x\n",
    "t_inference = torch.unsqueeze(t,axis=-1).clone().to(device)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    loss = torch.mean((output-prediction)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        \n",
    "        prediction = model(t_inference).detach().cpu()\n",
    "        plot_progress(t, GT, prediction, training_data)\n",
    "        files.append(save_progress(save_dir, 'nophys', iter))\n",
    "    \n",
    "        if (iter+1) % 10000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate the training progress\n",
    "make_gif(files, \"results/harmonic/nophysics.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic/nophysics.gif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training WITH Physics-Informed Loss Term\n",
    "\n",
    "Apparently, the baseline model without a physics loss term didn't generalize well to unseen time steps. Now, let's add a physics loss term to make it predict beyond training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "        \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic/pinn'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 30000\n",
    "N_COLLOCATION_POINTS = 30\n",
    "input = training_data[:,:1].clone().detach().to(device)    # t\n",
    "output = training_data[:,1:].clone().detach().to(device)  # x\n",
    "collocation_t = torch.linspace(0,Tmax,N_COLLOCATION_POINTS)\n",
    "collocation_pts = torch.unsqueeze(collocation_t, -1).clone().detach().requires_grad_(True).to(device)\n",
    "t_inference = torch.unsqueeze(t,axis=-1).clone().to(device)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    data_loss = torch.mean((output-prediction)**2)\n",
    "    \n",
    "    prediction_colloc = model(collocation_pts)\n",
    "    dx  = torch.autograd.grad(prediction_colloc, collocation_pts, torch.ones_like(prediction_colloc), create_graph=True)[0]\n",
    "    ddx  = torch.autograd.grad(dx, collocation_pts, torch.ones_like(dx), create_graph=True)[0]\n",
    "    residual = ddx + 2*zeta*omega0*dx + (omega0**2)*prediction_colloc\n",
    "    physics_loss = torch.mean(residual**2)\n",
    "\n",
    "    loss = data_loss + (1e-4)*physics_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}, physics: {physics_loss.detach().cpu().numpy():.5e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        \n",
    "        prediction = model(t_inference).detach().cpu()\n",
    "\n",
    "        plot_progress(t, GT, prediction, training_data, collocation_t)\n",
    "        files.append(save_progress(save_dir, 'pinn', iter))\n",
    "    \n",
    "        if (iter+1) % 10000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic/pinn.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic/pinn.gif\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-Driven Discovery\n",
    "\n",
    "Now, switching the gear a little bit, let's take a look at a different use of PINN, which is the discovery of physics. The previous example above was about finding the solution of a physics equation when the physics parameters were given. However, in the example we are going to see below, we assume that the physics parameters are unknown. For example, in real world, we may encounter a scenario where we make an observation of a physics phenomenon using sensors or imaging devices and want to figure out what physical parameters might govern the phenomena.\n",
    "\n",
    "To emulate the scenario, we re-sample the training data as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_sample = 3.0        # include the entire interval for trainig\n",
    "Nt_sample = int(Nt*Tmax_sample/Tmax)\n",
    "\n",
    "t_sample = torch.unsqueeze(t[0:Nt_sample:sample_stride], -1)\n",
    "GT_sample = GT[0:Nt_sample:sample_stride,:].clone()\n",
    "GT_sample += 0.02*torch.randn(GT_sample.shape)     # add noise to emulate real-world\n",
    "\n",
    "training_data = torch.hstack((t_sample, GT_sample)) \n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(t, GT[:,0], color='black', label = \"Ground Truth\")\n",
    "plt.scatter(training_data[:,0], training_data[:,1], color='orange', label='Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.title('Position')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_parameters(model)\n",
    "\n",
    "# Add zeta and omega0 to the list of parameters for optimization\n",
    "# We will pretend that we do not know the true zeta and omega0.\n",
    "omega_pred = torch.rand(1, device=device, requires_grad=True)   # GT: 2*pi = 6.283185307178\n",
    "zeta_pred = torch.rand(1, device=device, requires_grad=True)    # GT: 0.15\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [zeta_pred, omega_pred],lr=5e-4)\n",
    "\n",
    "# the rest of the process is pretty much the same as before...\n",
    "files = []\n",
    "\n",
    "save_dir = 'results/harmonic/pinn_discovery'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "MAX_ITER = 20000\n",
    "N_COLLOCATION_POINTS = 30\n",
    "input = training_data[:,:1].clone().detach().to(device)   # t\n",
    "output = training_data[:,1:].clone().detach().to(device)  # x\n",
    "collocation_t = torch.linspace(0,Tmax,N_COLLOCATION_POINTS)\n",
    "collocation_pts = torch.unsqueeze(collocation_t, -1).clone().detach().requires_grad_(True).to(device)\n",
    "t_inference = torch.unsqueeze(t,axis=-1).to(device)\n",
    "for iter in range(MAX_ITER):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(input)\n",
    "    data_loss = torch.mean((output-prediction)**2)\n",
    "    \n",
    "    prediction_colloc = model(collocation_pts)\n",
    "    dx  = torch.autograd.grad(prediction_colloc, collocation_pts, torch.ones_like(prediction_colloc), create_graph=True)[0]\n",
    "    ddx  = torch.autograd.grad(dx, collocation_pts, torch.ones_like(dx), create_graph=True)[0]\n",
    "    residual = ddx + 2*zeta_pred*omega_pred*dx + (omega_pred**2)*prediction_colloc  # note that we are using the predicted value of zeta and omega\n",
    "    physics_loss = torch.mean(residual**2)\n",
    "\n",
    "    loss = data_loss + (1e-4)*physics_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"{iter+1}/{MAX_ITER} - loss: {loss.detach().cpu().numpy():.5e}, physics: {physics_loss.detach().cpu().numpy():.5e}, zeta: {zeta_pred.detach().cpu().item():.3e}, omega0: {omega_pred.detach().cpu().item():.3e}\", end='\\r')\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (iter+1) % 100 == 0: \n",
    "        \n",
    "        prediction = model(t_inference).detach().cpu()\n",
    "\n",
    "        plot_progress(t, GT, prediction, training_data, collocation_t)\n",
    "        files.append(save_progress(save_dir, 'pinn', iter))\n",
    "    \n",
    "        if (iter+1) % 5000 == 0: plt.show()\n",
    "        else: plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(files, \"results/harmonic/pinn_discovery.gif\")\n",
    "IPython.display.Image(filename=\"results/harmonic/pinn_discovery.gif\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ground Truth: zeta={zeta}, omega0={omega0}\")\n",
    "print(f\"Discovered: zeta={zeta_pred.detach().item()}, omega0={omega_pred.detach().item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
